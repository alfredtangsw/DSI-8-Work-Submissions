{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages, Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_df = pd.read_csv('./datasets/combined_df.csv')\n",
    "#title_wordcount_df = pd.read_csv('./datasets/title_wordcount.csv')\n",
    "#post_wordcount_df = pd.read_csv('./datasets/post_wordcount.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1915\n"
     ]
    }
   ],
   "source": [
    "#finalcheck of dataframe before proceeding\n",
    "comb_df = comb_df.drop(columns='Unnamed: 0')\n",
    "print(comb_df.isnull().sum().sum())\n",
    "print(len(comb_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 key features are titles and posts\n",
    "#Titles could be highly informative features given that they tend to be succinct summaries of the post content\n",
    "#Lemmatised versions already made in previous steps, so they will be used\n",
    "\n",
    "X_titles = comb_df['titles_lemmatized']\n",
    "X_posts = comb_df['posts_lemmatized']\n",
    "y = comb_df['subreddit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Titles split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_titles_train, X_titles_test, y_titles_train, y_titles_test = train_test_split(X_titles, y,stratify=y,\n",
    "                                                                                random_state=1337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Posts split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_posts_train, X_posts_test, y_posts_train, y_posts_test = train_test_split(X_posts, y, stratify=y,\n",
    "                                                                            random_state=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all((y_titles_train == y_posts_train)==True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all((y_titles_test == y_posts_test)==True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style = \"color:green\"> Baseline: Naive Bayes Classifier (Multinomial)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Naive Bayes Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes = Pipeline([('vector',TfidfVectorizer()),     #get tfidf scores for each word in all documents \n",
    "                        ('multi_nb', MultinomialNB())])   #default values are used for baseline -- GridSearch will be done later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes: Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7828810020876826\n",
      "\n",
      "_____Scores for Titles_____\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     DaveRamsey       0.80      0.77      0.78       245\n",
      "personalfinance       0.77      0.80      0.78       234\n",
      "\n",
      "      micro avg       0.78      0.78      0.78       479\n",
      "      macro avg       0.78      0.78      0.78       479\n",
      "   weighted avg       0.78      0.78      0.78       479\n",
      "\n"
     ]
    }
   ],
   "source": [
    "naive_bayes.fit(X_titles_train,y_titles_train)          #fit training data to naive bayes pipeline\n",
    "\n",
    "naive_ypred = naive_bayes.predict(X_titles_test)        # predict y using X_test\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_titles_test,naive_ypred))\n",
    "print('\\n_____Scores for Titles_____')\n",
    "print(classification_report(y_titles_test,naive_ypred,target_names=['DaveRamsey','personalfinance']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes: Post Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8622129436325678\n",
      "\n",
      "_____Scores for Posts_____\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     DaveRamsey       0.84      0.91      0.87       245\n",
      "personalfinance       0.90      0.81      0.85       234\n",
      "\n",
      "      micro avg       0.86      0.86      0.86       479\n",
      "      macro avg       0.87      0.86      0.86       479\n",
      "   weighted avg       0.87      0.86      0.86       479\n",
      "\n"
     ]
    }
   ],
   "source": [
    "naive_bayes.fit(X_posts_train,y_posts_train)\n",
    "\n",
    "naive_ypred = naive_bayes.predict(X_posts_test)\n",
    "posts_nb_base_acc = accuracy_score(y_posts_test,naive_ypred)\n",
    "\n",
    "print('accuracy %s' % posts_nb_base_acc)\n",
    "print('\\n_____Scores for Posts_____')\n",
    "print(classification_report(y_posts_test,naive_ypred,target_names=['DaveRamsey','personalfinance']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: Logistic Regression\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.778705636743215\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     DaveRamsey       0.79      0.78      0.78       245\n",
      "personalfinance       0.77      0.78      0.78       234\n",
      "\n",
      "      micro avg       0.78      0.78      0.78       479\n",
      "      macro avg       0.78      0.78      0.78       479\n",
      "   weighted avg       0.78      0.78      0.78       479\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logisticreg = Pipeline([('vector', TfidfVectorizer()),\n",
    "                        ('logisticreg', LogisticRegression(solver='liblinear',random_state=1337))])\n",
    "\n",
    "logisticreg.fit(X_titles_train, y_titles_train)\n",
    "\n",
    "logistic_ypred = logisticreg.predict(X_titles_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(logistic_ypred, y_titles_test))\n",
    "print(classification_report(y_titles_test, logistic_ypred,target_names=['DaveRamsey','personalfinance']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8622129436325678\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     DaveRamsey       0.87      0.87      0.87       245\n",
      "personalfinance       0.86      0.86      0.86       234\n",
      "\n",
      "      micro avg       0.86      0.86      0.86       479\n",
      "      macro avg       0.86      0.86      0.86       479\n",
      "   weighted avg       0.86      0.86      0.86       479\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logisticreg.fit(X_posts_train, y_posts_train)\n",
    "\n",
    "logistic_ypred = logisticreg.predict(X_posts_test)\n",
    "posts_logreg_base_acc = accuracy_score(logistic_ypred, y_posts_test)\n",
    "\n",
    "print('accuracy %s' % posts_logreg_base_acc)\n",
    "print(classification_report(y_posts_test, logistic_ypred,target_names=['DaveRamsey','personalfinance']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = Pipeline([('vector',TfidfVectorizer()),\n",
    "                ('supvec',svm.SVC(C=1.0,\n",
    "                                 kernel='linear',\n",
    "                                 degree=3,\n",
    "                                 gamma='auto',\n",
    "                                 random_state=1337))\n",
    "               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7620041753653445\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     DaveRamsey       0.77      0.76      0.76       245\n",
      "personalfinance       0.75      0.77      0.76       234\n",
      "\n",
      "      micro avg       0.76      0.76      0.76       479\n",
      "      macro avg       0.76      0.76      0.76       479\n",
      "   weighted avg       0.76      0.76      0.76       479\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVM.fit(X_titles_train,y_titles_train)\n",
    "svm_ypred = SVM.predict(X_titles_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(svm_ypred, y_titles_test))\n",
    "print(classification_report(y_titles_test, svm_ypred,target_names=['DaveRamsey','personalfinance']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8538622129436325\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     DaveRamsey       0.88      0.83      0.85       245\n",
      "personalfinance       0.83      0.88      0.85       234\n",
      "\n",
      "      micro avg       0.85      0.85      0.85       479\n",
      "      macro avg       0.85      0.85      0.85       479\n",
      "   weighted avg       0.86      0.85      0.85       479\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVM.fit(X_posts_train,y_posts_train)\n",
    "SVM_ypred = SVM.predict(X_posts_test)\n",
    "posts_SVM_base_acc = accuracy_score(SVM_ypred, y_posts_test)\n",
    "\n",
    "print('accuracy %s' % posts_SVM_base_acc)\n",
    "print(classification_report(y_posts_test, SVM_ypred,target_names=['DaveRamsey','personalfinance']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: Stochastic Gradient Descent Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7620041753653445\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     DaveRamsey       0.75      0.73      0.74       245\n",
      "personalfinance       0.72      0.74      0.73       234\n",
      "\n",
      "      micro avg       0.73      0.73      0.73       479\n",
      "      macro avg       0.73      0.73      0.73       479\n",
      "   weighted avg       0.74      0.73      0.73       479\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alfred\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "stochastic = Pipeline([('vector', TfidfVectorizer()),\n",
    "                       ('stoch', SGDClassifier(random_state=1337))])\n",
    "\n",
    "stochastic.fit(X_titles_train, y_titles_train)\n",
    "\n",
    "stochastic_ypred = stochastic.predict(X_titles_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(svm_ypred, y_titles_test))\n",
    "print(classification_report(y_titles_test, stochastic_ypred,target_names=['DaveRamsey','personalfinance']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8204592901878914\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     DaveRamsey       0.86      0.78      0.82       245\n",
      "personalfinance       0.79      0.87      0.83       234\n",
      "\n",
      "      micro avg       0.82      0.82      0.82       479\n",
      "      macro avg       0.82      0.82      0.82       479\n",
      "   weighted avg       0.82      0.82      0.82       479\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stochastic.fit(X_posts_train, y_posts_train)\n",
    "\n",
    "stoch_ypred = stochastic.predict(X_posts_test)\n",
    "posts_stoch_base_acc = accuracy_score(stoch_ypred, y_posts_test)\n",
    "\n",
    "print('accuracy %s' % posts_stoch_base_acc)\n",
    "print(classification_report(y_posts_test, stoch_ypred,target_names=['DaveRamsey','personalfinance']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GridSearchCV for all models\n",
    "\n",
    "param_grid_nb = [{'vector__ngram_range':[(1,1),(1,2),(1,3),(1,4),(1,5)],\n",
    "                  'vector__max_df':[0.9,0.95],\n",
    "                  'vector__min_df':[0.0001,0.001,0.01],\n",
    "                  'multi_nb__alpha':[1e-5*10**i for i in range(0,6)],\n",
    "                  'multi_nb__fit_prior':[True,False]\n",
    "                 }]\n",
    "\n",
    "param_grid_logisticreg = [{'vector__ngram_range':[(1,1),(1,2),(1,3),(1,4),(1,5)],\n",
    "                           'vector__max_df':[0.9,0.95],\n",
    "                           'vector__min_df':[0.0001,0.001,0.01],\n",
    "                           'logisticreg__penalty':['l1','l2'],\n",
    "                           'logisticreg__C':list(np.linspace(1.0,1.5,6)),\n",
    "                           'logisticreg__max_iter':[1e2,1e3,1e4,1e5]\n",
    "                          }]\n",
    "\n",
    "param_grid_SVM = [{'vector__ngram_range':[(1,1),(1,2),(1,3),(1,4),(1,5)],\n",
    "                   'vector__max_df':[0.9,0.95],\n",
    "                   'vector__min_df':[0.0001,0.001,0.01],\n",
    "                   'supvec__C':list(np.linspace(1.0,1.5,6)),\n",
    "                   'supvec__kernel':['rbf','linear','sigmoid']\n",
    "                  }] \n",
    "\n",
    "param_grid_stochastic = [{'vector__ngram_range':[(1,1),(1,2),(1,3),(1,4),(1,5)],\n",
    "                          'vector__max_df':[0.9,0.95],\n",
    "                          'vector__min_df':[0.0001,0.001,0.01],\n",
    "                          'stoch__penalty':['l1','l2'],\n",
    "                          'stoch__alpha':[1e-6*10**i for i in range(0,8)],\n",
    "                          #'stoch__max_iter':[10,100,1000]\n",
    "                         }]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_grid = GridSearchCV(estimator = naive_bayes,\n",
    "                       param_grid=param_grid_nb,\n",
    "                       scoring='accuracy'\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alfred\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "titles_grid_result_nb = nb_grid.fit(X_titles_train,y_titles_train)\n",
    "titles_best_params_nb = nb_grid.best_params_\n",
    "titles_best_acc_nb = nb_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alfred\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "posts_grid_result_nb = nb_grid.fit(X_posts_train,y_posts_train)\n",
    "posts_best_params_nb = nb_grid.best_params_\n",
    "posts_best_acc_nb = nb_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'multi_nb__alpha': 1.0,\n",
       " 'multi_nb__fit_prior': True,\n",
       " 'vector__max_df': 0.9,\n",
       " 'vector__min_df': 0.0001,\n",
       " 'vector__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_best_params_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7458217270194986"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_best_acc_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'multi_nb__alpha': 1.0,\n",
       " 'multi_nb__fit_prior': False,\n",
       " 'vector__max_df': 0.9,\n",
       " 'vector__min_df': 0.0001,\n",
       " 'vector__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_best_params_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8649025069637883"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_best_acc_nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_grid = GridSearchCV(estimator = logisticreg,\n",
    "                           param_grid=param_grid_logisticreg,\n",
    "                           scoring='accuracy'\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alfred\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "titles_grid_result_logreg = logreg_grid.fit(X_titles_train,y_titles_train)\n",
    "titles_best_params_logreg = logreg_grid.best_params_\n",
    "titles_best_acc_logreg = logreg_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alfred\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "posts_grid_result_logreg = logreg_grid.fit(X_posts_train,y_posts_train)\n",
    "posts_best_params_logreg = logreg_grid.best_params_\n",
    "posts_best_acc_logreg = logreg_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logisticreg__C': 1.0,\n",
       " 'logisticreg__max_iter': 100.0,\n",
       " 'logisticreg__penalty': 'l2',\n",
       " 'vector__max_df': 0.9,\n",
       " 'vector__min_df': 0.0001,\n",
       " 'vector__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_best_params_logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.754874651810585"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_best_acc_logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logisticreg__C': 1.1,\n",
       " 'logisticreg__max_iter': 100.0,\n",
       " 'logisticreg__penalty': 'l2',\n",
       " 'vector__max_df': 0.9,\n",
       " 'vector__min_df': 0.0001,\n",
       " 'vector__ngram_range': (1, 4)}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_best_params_logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8586350974930362"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_best_acc_logreg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_grid = GridSearchCV(estimator = SVM,\n",
    "                        param_grid = param_grid_SVM,\n",
    "                        scoring = 'accuracy'\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alfred\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "titles_grid_result_SVM = SVM_grid.fit(X_titles_train,y_titles_train)\n",
    "titles_best_params_SVM = SVM_grid.best_params_\n",
    "titles_best_acc_SVM = SVM_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alfred\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "posts_grid_result_SVM = SVM_grid.fit(X_posts_train,y_posts_train)\n",
    "posts_best_params_SVM = SVM_grid.best_params_\n",
    "posts_best_acc_SVM = SVM_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7506963788300836"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_best_acc_SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'supvec__C': 1.4,\n",
       " 'supvec__kernel': 'linear',\n",
       " 'vector__max_df': 0.9,\n",
       " 'vector__min_df': 0.0001,\n",
       " 'vector__ngram_range': (1, 3)}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_best_params_SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8523676880222841"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_best_acc_SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'supvec__C': 1.1,\n",
       " 'supvec__kernel': 'linear',\n",
       " 'vector__max_df': 0.9,\n",
       " 'vector__min_df': 0.0001,\n",
       " 'vector__ngram_range': (1, 5)}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_best_params_SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Classifier GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoch_grid = GridSearchCV(estimator = stochastic,\n",
    "                           param_grid=param_grid_stochastic,\n",
    "                           scoring='accuracy'\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alfred\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Alfred\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "titles_grid_result_stoch = stoch_grid.fit(X_titles_train,y_titles_train)\n",
    "titles_best_params_stoch = stoch_grid.best_params_\n",
    "titles_best_acc_stoch = stoch_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alfred\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Alfred\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "posts_grid_result_stoch = stoch_grid.fit(X_posts_train,y_posts_train)\n",
    "posts_best_params_stoch = stoch_grid.best_params_\n",
    "posts_best_acc_stoch = stoch_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stoch__alpha': 0.001,\n",
       " 'stoch__penalty': 'l2',\n",
       " 'vector__max_df': 0.9,\n",
       " 'vector__min_df': 0.0001,\n",
       " 'vector__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_best_params_stoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7534818941504178"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_best_acc_stoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stoch__alpha': 9.999999999999999e-05,\n",
       " 'stoch__penalty': 'l2',\n",
       " 'vector__max_df': 0.9,\n",
       " 'vector__min_df': 0.0001,\n",
       " 'vector__ngram_range': (1, 4)}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_best_params_stoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8530640668523677"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_best_acc_stoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Modelling Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes_fin = Pipeline([('vector',TfidfVectorizer(ngram_range=(1,2),\n",
    "                                                     min_df=0.0001,\n",
    "                                                     max_df=0.9)),     #get tfidf scores for each word in all documents \n",
    "                            ('multi_nb', MultinomialNB(alpha=1.0,\n",
    "                                                       fit_prior=False))\n",
    "                           ])   #default values are used for baseline -- GridSearch will be done later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes: Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8768267223382046\n",
      "\n",
      "_____Scores for Posts_____\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     DaveRamsey       0.87      0.89      0.88       245\n",
      "personalfinance       0.89      0.86      0.87       234\n",
      "\n",
      "      micro avg       0.88      0.88      0.88       479\n",
      "      macro avg       0.88      0.88      0.88       479\n",
      "   weighted avg       0.88      0.88      0.88       479\n",
      "\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_fin.fit(X_posts_train,y_posts_train)          #fit training data to naive bayes pipeline\n",
    "\n",
    "naive_ypred_fin = naive_bayes_fin.predict(X_posts_test)        # predict y using X_test\n",
    "nb_fin_acc = accuracy_score(y_posts_test,naive_ypred_fin)\n",
    "\n",
    "print('accuracy %s' % nb_fin_acc)\n",
    "print('\\n_____Scores for Posts_____')\n",
    "print(classification_report(y_posts_test,naive_ypred_fin,target_names=['DaveRamsey','personalfinance']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Logistic Regression\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticreg_fin = Pipeline([('vector', TfidfVectorizer(ngram_range=(1,4),\n",
    "                                                      min_df=0.0001,\n",
    "                                                      max_df=0.9)),\n",
    "                            ('logisticreg', LogisticRegression(C=1.1,\n",
    "                                                               max_iter=100,\n",
    "                                                               penalty='l2',\n",
    "                                                               random_state=1337))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8810020876826722\n",
      "\n",
      "_____Scores for Posts_____\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     DaveRamsey       0.89      0.87      0.88       245\n",
      "personalfinance       0.87      0.89      0.88       234\n",
      "\n",
      "      micro avg       0.88      0.88      0.88       479\n",
      "      macro avg       0.88      0.88      0.88       479\n",
      "   weighted avg       0.88      0.88      0.88       479\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logisticreg_fin.fit(X_posts_train, y_posts_train)\n",
    "\n",
    "logistic_ypred_fin = logisticreg_fin.predict(X_posts_test)\n",
    "logistic_fin_acc = accuracy_score(logistic_ypred_fin, y_posts_test)\n",
    "\n",
    "print('accuracy %s' % logistic_fin_acc)\n",
    "print('\\n_____Scores for Posts_____')\n",
    "print(classification_report(y_posts_test, logistic_ypred_fin,target_names=['DaveRamsey','personalfinance']))\n",
    "\n",
    "#Logistic regression may perform better on a larger dataset. https://medium.com/@sangha_deb/naive-bayes-vs-logistic-regression-a319b07a5d4c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_fin=Pipeline([('vector', TfidfVectorizer(ngram_range=(1, 5),\n",
    "                                           min_df= 0.0001,\n",
    "                                           max_df=0.9)),\n",
    "                  ('supvec', svm.SVC(C=1.1,\n",
    "                                     kernel='linear',\n",
    "                                     gamma='auto',\n",
    "                                     random_state=1337))\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8663883089770354\n",
      "\n",
      "_____Scores for Posts_____\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     DaveRamsey       0.90      0.83      0.86       245\n",
      "personalfinance       0.83      0.91      0.87       234\n",
      "\n",
      "      micro avg       0.87      0.87      0.87       479\n",
      "      macro avg       0.87      0.87      0.87       479\n",
      "   weighted avg       0.87      0.87      0.87       479\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVM_fin.fit(X_posts_train,y_posts_train)\n",
    "\n",
    "SVM_fin_ypred = SVM_fin.predict(X_posts_test)\n",
    "SVM_fin_acc = accuracy_score(SVM_fin_ypred, y_posts_test)\n",
    "\n",
    "print('accuracy %s' %SVM_fin_acc)\n",
    "print('\\n_____Scores for Posts_____')\n",
    "print(classification_report(y_posts_test, SVM_fin_ypred,target_names=['DaveRamsey','personalfinance']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "stochastic_fin = Pipeline([('vector', TfidfVectorizer(ngram_range=(1,5),\n",
    "                                                     min_df=0.0001,\n",
    "                                                     max_df=0.9)),\n",
    "                           ('stoch', SGDClassifier(alpha=1e-04,\n",
    "                                                   penalty='l2',\n",
    "                                                   random_state=1337))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alfred\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.872651356993737\n",
      "\n",
      "_____Scores for Posts_____\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     DaveRamsey       0.92      0.82      0.87       245\n",
      "personalfinance       0.83      0.93      0.88       234\n",
      "\n",
      "      micro avg       0.87      0.87      0.87       479\n",
      "      macro avg       0.88      0.87      0.87       479\n",
      "   weighted avg       0.88      0.87      0.87       479\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stochastic_fin.fit(X_posts_train, y_posts_train)\n",
    "\n",
    "stoch_ypred_fin = stochastic_fin.predict(X_posts_test)\n",
    "stoch_fin_acc = accuracy_score(stoch_ypred_fin, y_titles_test)\n",
    "\n",
    "print('accuracy %s' % stoch_fin_acc)\n",
    "print('\\n_____Scores for Posts_____')\n",
    "print(classification_report(y_titles_test, stoch_ypred_fin,target_names=['DaveRamsey','personalfinance']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score Tabulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = pd.DataFrame({'Baseline':[posts_nb_base_acc,posts_logreg_base_acc,posts_SVM_base_acc,posts_stoch_base_acc],\n",
    "                         'GridSearchCV':[posts_best_acc_nb,posts_best_acc_logreg,posts_best_acc_SVM,posts_best_acc_stoch],\n",
    "                         'Tuned':[nb_fin_acc,logistic_fin_acc,SVM_fin_acc,stoch_fin_acc],\n",
    "                         'best_params':[posts_best_params_nb,posts_best_params_logreg,posts_best_params_SVM,posts_best_params_stoch]\n",
    "                        },\n",
    "                        index=['MultinomialNB','LogReg','Support Vector Machine','Stoch Grad Desc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline</th>\n",
       "      <th>GridSearchCV</th>\n",
       "      <th>Tuned</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.862213</td>\n",
       "      <td>0.864903</td>\n",
       "      <td>0.876827</td>\n",
       "      <td>{'multi_nb__alpha': 1.0, 'multi_nb__fit_prior'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg</th>\n",
       "      <td>0.862213</td>\n",
       "      <td>0.858635</td>\n",
       "      <td>0.881002</td>\n",
       "      <td>{'logisticreg__C': 1.1, 'logisticreg__max_iter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <td>0.853862</td>\n",
       "      <td>0.852368</td>\n",
       "      <td>0.866388</td>\n",
       "      <td>{'supvec__C': 1.1, 'supvec__kernel': 'linear',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stoch Grad Desc</th>\n",
       "      <td>0.820459</td>\n",
       "      <td>0.853064</td>\n",
       "      <td>0.872651</td>\n",
       "      <td>{'stoch__alpha': 9.999999999999999e-05, 'stoch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Baseline  GridSearchCV     Tuned  \\\n",
       "MultinomialNB           0.862213      0.864903  0.876827   \n",
       "LogReg                  0.862213      0.858635  0.881002   \n",
       "Support Vector Machine  0.853862      0.852368  0.866388   \n",
       "Stoch Grad Desc         0.820459      0.853064  0.872651   \n",
       "\n",
       "                                                              best_params  \n",
       "MultinomialNB           {'multi_nb__alpha': 1.0, 'multi_nb__fit_prior'...  \n",
       "LogReg                  {'logisticreg__C': 1.1, 'logisticreg__max_iter...  \n",
       "Support Vector Machine  {'supvec__C': 1.1, 'supvec__kernel': 'linear',...  \n",
       "Stoch Grad Desc         {'stoch__alpha': 9.999999999999999e-05, 'stoch...  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999999"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9.999999999999999e-05/1e-04"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
